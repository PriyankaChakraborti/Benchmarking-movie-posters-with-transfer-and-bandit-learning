{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import dill\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep list for after browser loaded\n",
    "loading_sleep = [7,8,9,10]\n",
    "# Sleep list for downloading posters\n",
    "store_image_sleep = [0.1,0.2,0.3] # Worked for [0.5,1]\n",
    "# Sleep list for going to next page\n",
    "next_page_sleep = [5,7,8,10]\n",
    "# List of all genres available on IMDB\n",
    "genres= ['Action','Adventure','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy','History',\\\n",
    "         'Horror','Musical','Mystery','Romance','Sci-Fi','Sport','Thriller','War','Western']\n",
    "\n",
    "genre_list = ['Western']\n",
    "start_num = 6001 # Movie number to start search on\n",
    "max_pages = 24 # This is the number of pages to go through before saving dataframe\n",
    "num_res_per_page = 250 # Choose 50 or 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### COMPLETED ##########\n",
    "# Bryan Mac has (1-6000) for Action, Adventure, Animation, Biography, Comedy, Crime, Drama, Family, Fantasy,\n",
    "#                            History, Horror, Musical, Mystery, Romance, Sci-Fi, Sport, Thriller, War, Western\n",
    "# Bryan PC has (6001-12000) for Action, Adventure, Animation, Biography, Comedy, Crime, Drama, Family, Fantasy,\n",
    "#                               History, Horror, Musical, Mystery, Romance, Sci-Fi, Sport, Thriller, War, ...\n",
    "\n",
    "###### CATEGORY DETAILS ###########\n",
    "# Action has 44,230\n",
    "# Adventure has 21,924\n",
    "# Animation has 6,247\n",
    "# Biography has 6,357\n",
    "# Comedy has 88,928\n",
    "# Crime has 29,671\n",
    "# Drama has 182,244\n",
    "# Family has 13,830\n",
    "# Fantasy has 13,396\n",
    "# History has 7,184\n",
    "# Horror has 27,973\n",
    "# Musical has 9,407\n",
    "# Mystery has 14,752\n",
    "# Romance has 43,713\n",
    "# Sci-Fi has 13,023\n",
    "# Sport has 4,712\n",
    "# Thriller has 41,818\n",
    "# War has 8,732\n",
    "# Western has 8,414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to which we save the downloaded posters\n",
    "dir_path_base='/Users/bryan/Box Sync/CSE496-final/posters'\n",
    "#creates directory if not already there\n",
    "if not os.path.exists(dir_path_base):\n",
    "    os.mkdir(dir_path_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition to download and save posters\n",
    "def store_image(dir_path,link,name,year):\n",
    "    sleep(random.choice(store_image_sleep))\n",
    "    \n",
    "    try_count = 0\n",
    "    while try_count <=20: # Try 20 times\n",
    "        try_count += 1\n",
    "        try:\n",
    "            response=requests.get(link)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            image = soup.find('div', class_ = \"poster\")\n",
    "            file_name = name+'_'+year+'.jpg'\n",
    "            urllib.request.urlretrieve(image.img['src'],os.path.join(dir_path, file_name))\n",
    "            return 1\n",
    "        except:\n",
    "            continue\n",
    "    # Returned if movie never able to be downloaded\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main definition for scraping pages\n",
    "def get_links_by_genre(genre_in, start_num, num_res_per_page, max_pages):\n",
    "    genre_print = genre_in.upper()\n",
    "    \n",
    "    dir_path= dir_path_base + '/' + genre_in + '-' + str(start_num) + '-' + str(num_res_per_page)\n",
    "    \n",
    "    #creates directory if not already there\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    \n",
    "    '''Driver code for getting all image links by genre'''\n",
    "    \n",
    "    # Define options for the browser\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.set_headless()\n",
    "    \n",
    "    # Initialize empty listss\n",
    "    title=[]\n",
    "    rating=[]\n",
    "    meta_score=[]\n",
    "    year=[]\n",
    "    votes=[]\n",
    "    genre=[]\n",
    "    links = []\n",
    "    page_num = 1\n",
    "    \n",
    "    # Initialize movie number to start on\n",
    "    curr_movie_num = start_num\n",
    "    \n",
    "    while page_num<=max_pages:\n",
    "        \n",
    "        print('...... %s SEARCH PAGE (%i out of %i) ......' %(genre_print,page_num,max_pages))\n",
    "        \n",
    "        # Define URL for this page\n",
    "        url='https://www.imdb.com/search/title/?title_type=feature&genres='+genre_in.lower()+'&count='+str(num_res_per_page)+'&start='+str(curr_movie_num)+'&explore=genres&ref_=adv_nxt'\n",
    "        browser = webdriver.Chrome(executable_path='/usr/local/bin/chromedriver',chrome_options=options)\n",
    "        #scrapes the very first page into the soup#\n",
    "        \n",
    "        # Below allows us to automate searching pages which do not exist\n",
    "        try:\n",
    "            browser.get(url)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Pause to give the broswer time to load any animations or ads\n",
    "        sleep(random.choice(loading_sleep))\n",
    "        soup = BeautifulSoup(browser.page_source,\"html.parser\")\n",
    "        \n",
    "        # Update current page number for next time\n",
    "        curr_movie_num += num_res_per_page\n",
    "    \n",
    "        movie_all_page=soup.find_all('div',class_='lister-item mode-advanced')\n",
    "        for item in movie_all_page:\n",
    "            \n",
    "            # scrape the name\n",
    "            name=item.h3.a.text\n",
    "            \n",
    "            # Translate to closest unicode version of title name\n",
    "            name = unidecode.unidecode(name)\n",
    "            \n",
    "            # Sanitize name before continuing\n",
    "            name = name.replace(r'/','_')\n",
    "            name = name.replace(r':','_')\n",
    "            name = name.replace(r'\\\\','_')\n",
    "            name = name.replace(r'*','_')\n",
    "            name = name.replace(r'?','_')\n",
    "            name = name.replace(r'<','_')\n",
    "            name = name.replace(r'>','_')\n",
    "            name = name.replace(r\"'\",'_')\n",
    "            name = name.replace(r'!','_')\n",
    "            \n",
    "            # Scrape the rating\n",
    "            if item.find('span',class_='value') is not None:\n",
    "                imdb_rating = item.find('span',class_='value').text\n",
    "            else: # If not rating on IMDB the movie has not yet released\n",
    "                continue\n",
    "    \n",
    "            # Scrape the year\n",
    "            curr_year = item.h3.find('span', class_ = 'lister-item-year').text[-5:-1]\n",
    "            no_year = False\n",
    "            if not curr_year:\n",
    "                no_year = True\n",
    "            \n",
    "            # Run only if there is a year\n",
    "            if no_year == False:\n",
    "                # Skip movie if released starting in 2020 or year given not integer\n",
    "                try:\n",
    "                    if int(curr_year) > 2019:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "                #scrape url of image,then download and store it\n",
    "                saved_bool = store_image(dir_path,str('https://www.imdb.com'+item.h3.a['href']),name,curr_year)\n",
    "            else:\n",
    "                saved_bool = 0\n",
    "            \n",
    "            # Only append any of the below if image was able to be scraped\n",
    "            if saved_bool == 1:\n",
    "                \n",
    "                # Saves url for each movie's page\n",
    "                links.append(str('https://www.imdb.com'+item.h3.a['href']))\n",
    "                \n",
    "                rating.append(imdb_rating)\n",
    "                    \n",
    "                #if the movie has a meta score only then include it.Eliminates pre and post production movies\n",
    "                #append meta-score\n",
    "                if item.find('div', class_ = 'ratings-metascore') is not None:\n",
    "                    curr_meta_score = item.find('div',class_='ratings-metascore').text.split()[0]\n",
    "                    meta_score.append(curr_meta_score)\n",
    "                else:\n",
    "                    meta_score.append('NaN')\n",
    "                # Append the name\n",
    "                title.append(name)\n",
    "                # Append year of current movie\n",
    "                year.append(curr_year)\n",
    "                \n",
    "                # Scrape the number of votes\n",
    "                if item.find('span',attrs={'name':'nv'}) is not None:\n",
    "                    try:\n",
    "                        votes.append(int(item.find('span',attrs={'name':'nv'})['data-value']))\n",
    "                    except:\n",
    "                        votes.append('NaN')\n",
    "                else:\n",
    "                    votes.append('NaN')\n",
    "                    \n",
    "                # Finally store genres (Note we split on comma and strip white space)\n",
    "                genre.append([x.strip() for x in item.find('span',class_='genre').text.split(',')])\n",
    "                \n",
    "        #close old browser and pause for the set pause time\n",
    "        browser.quit()\n",
    "        sleep(random.choice(next_page_sleep))\n",
    "        \n",
    "        page_num += 1\n",
    "        \n",
    "    \n",
    "    #convert to pandas data frame and store to csv\n",
    "    movie_ratings = pd.DataFrame({'movie': title, 'year': year, 'imdb': rating, 'metascore': meta_score,\n",
    "                                  'votes': votes, 'genre':genre, 'link':links})\n",
    "    print('ALL SEARCH PAGES COMPLETED FOR CHOSEN GENRE')\n",
    "    \n",
    "    return movie_ratings\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: use setter for headless property instead of set_headless\n",
      "  app.launch_new_instance()\n",
      "/Users/bryan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...... WESTERN SEARCH PAGE (1 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (2 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (3 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (4 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (5 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (6 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (7 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (8 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (9 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (10 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (11 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (12 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (13 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (14 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (15 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (16 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (17 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (18 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (19 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (20 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (21 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (22 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (23 out of 24) ......\n",
      "...... WESTERN SEARCH PAGE (24 out of 24) ......\n",
      "ALL SEARCH PAGES COMPLETED FOR CHOSEN GENRE\n",
      "It took 321 minutes to complete Western\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run over chosen genres in list\n",
    "\n",
    "for genre in genre_list:\n",
    "    t0 = time.time()\n",
    "    movie_ratings = get_links_by_genre(genre, start_num, num_res_per_page, max_pages)\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('It took %i minutes to complete %s' %(int((t1-t0)/60),genre))\n",
    "    print('')\n",
    "\n",
    "    # Save to csv\n",
    "    movie_ratings.to_csv(dir_path_base + r'/' + genre + '-' + str(start_num) + '-' + str(num_res_per_page) + '.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
